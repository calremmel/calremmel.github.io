<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Chris Remmel</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2019-04-20T00:00:00-04:00</updated><entry><title>Fraud Detection in Python: Part One</title><link href="/fraud-detection-part-one.html" rel="alternate"></link><published>2019-04-20T00:00:00-04:00</published><updated>2019-04-20T00:00:00-04:00</updated><author><name>Chris Remmel</name></author><id>tag:None,2019-04-20:/fraud-detection-part-one.html</id><summary type="html">&lt;h1&gt;Fraud Detection in Python: Part One&lt;/h1&gt;
&lt;h2&gt;Visualization and Unbalanced Classes&lt;/h2&gt;
&lt;p&gt;&lt;img alt="png" src="/images/pca_fraud_title.png"&gt;&lt;/p&gt;
&lt;p&gt;Fraud detection is an important area of business where machine learning techniques have a particularly powerful use case. While fraud detection as a discipline predates the widespread popularity of machine learning, traditional techniques rely primarily on rules of thumb for …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Fraud Detection in Python: Part One&lt;/h1&gt;
&lt;h2&gt;Visualization and Unbalanced Classes&lt;/h2&gt;
&lt;p&gt;&lt;img alt="png" src="/images/pca_fraud_title.png"&gt;&lt;/p&gt;
&lt;p&gt;Fraud detection is an important area of business where machine learning techniques have a particularly powerful use case. While fraud detection as a discipline predates the widespread popularity of machine learning, traditional techniques rely primarily on rules of thumb for flagging potentially fraudulent behavior. These rules can yield impressive results, but they cannot deal with interactions between different variables or improve over time the way a machine learning model can.&lt;/p&gt;
&lt;p&gt;This is part one in a multi-part deep dive into the latest and greatest in fraud detection techniques using machine learning in the Python programming language. I'll be going through the very latest methods for predicting rare events like fraud, starting from the basics and proceeding through the cutting edge.&lt;/p&gt;
&lt;p&gt;This series will be a set of living documents, and I will be updating them as much as I can as new ideas arise and as I learn more myself! Updates will be logged at the bottom of the page, so check there to see if there is anything new.&lt;/p&gt;
&lt;h1&gt;Visualizing Fraud&lt;/h1&gt;
&lt;p&gt;Part of what makes it so difficult to detect fraud is that &lt;strong&gt;fraud is rare.&lt;/strong&gt; Within any given dataset of transactions, there will usually be far more legitimate cases than fraudulent ones. This makes it difficult to build a profile for what might distinguish fraud from non-fraud, and it makes it very difficult to avoid flagging legitimate transactions as fraud inadvertently when you try.&lt;/p&gt;
&lt;p&gt;To get a sense of this, it is useful to have a way to visualize the frequency of fraud versus non-fraud. That's where we'll start.&lt;/p&gt;
&lt;p&gt;Throughout this series, we'll be working with &lt;strong&gt;Synthetic Financial Datasets For Fraud Detection,&lt;/strong&gt; generously provided by the Digital Forensics Research Group from NTNU in Gjøvik, Norway. An explanation of the dataset, the data dictionary, and the data itself are all available on Kaggle. &lt;a href="https://www.kaggle.com/ntnu-testimon/paysim1"&gt;Feel free to download it if you would like to follow along&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, let's import the libraries we'll need, and take a first glance at the dataset.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.decomposition&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;../data/raw/PS_20174392719_1491204439457_log.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;step&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;amount&lt;/th&gt;
      &lt;th&gt;nameOrig&lt;/th&gt;
      &lt;th&gt;oldbalanceOrg&lt;/th&gt;
      &lt;th&gt;newbalanceOrig&lt;/th&gt;
      &lt;th&gt;nameDest&lt;/th&gt;
      &lt;th&gt;oldbalanceDest&lt;/th&gt;
      &lt;th&gt;newbalanceDest&lt;/th&gt;
      &lt;th&gt;isFraud&lt;/th&gt;
      &lt;th&gt;isFlaggedFraud&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;PAYMENT&lt;/td&gt;
      &lt;td&gt;9839.64&lt;/td&gt;
      &lt;td&gt;C1231006815&lt;/td&gt;
      &lt;td&gt;170136.0&lt;/td&gt;
      &lt;td&gt;160296.36&lt;/td&gt;
      &lt;td&gt;M1979787155&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;PAYMENT&lt;/td&gt;
      &lt;td&gt;1864.28&lt;/td&gt;
      &lt;td&gt;C1666544295&lt;/td&gt;
      &lt;td&gt;21249.0&lt;/td&gt;
      &lt;td&gt;19384.72&lt;/td&gt;
      &lt;td&gt;M2044282225&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;TRANSFER&lt;/td&gt;
      &lt;td&gt;181.00&lt;/td&gt;
      &lt;td&gt;C1305486145&lt;/td&gt;
      &lt;td&gt;181.0&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;C553264065&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;CASH_OUT&lt;/td&gt;
      &lt;td&gt;181.00&lt;/td&gt;
      &lt;td&gt;C840083671&lt;/td&gt;
      &lt;td&gt;181.0&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;C38997010&lt;/td&gt;
      &lt;td&gt;21182.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;PAYMENT&lt;/td&gt;
      &lt;td&gt;11668.14&lt;/td&gt;
      &lt;td&gt;C2048537720&lt;/td&gt;
      &lt;td&gt;41554.0&lt;/td&gt;
      &lt;td&gt;29885.86&lt;/td&gt;
      &lt;td&gt;M1230701703&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
RangeIndex: 6362620 entries, 0 to 6362619
Data columns (total 11 columns):
step              int64
type              object
amount            float64
nameOrig          object
oldbalanceOrg     float64
newbalanceOrig    float64
nameDest          object
oldbalanceDest    float64
newbalanceDest    float64
isFraud           int64
isFlaggedFraud    int64
dtypes: float64(5), int64(3), object(3)
memory usage: 534.0+ MB
None
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is a large dataset with well over six-million entries. Let's have a look at the data dictionary so we know what kind of information we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;step&lt;/strong&gt; - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;type&lt;/strong&gt; - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;amount&lt;/strong&gt; - amount of the transaction in local currency.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nameOrig&lt;/strong&gt; - customer who started the transaction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;oldbalanceOrg&lt;/strong&gt; - initial balance before the transaction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;newbalanceOrig&lt;/strong&gt; - new balance after the transaction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nameDest&lt;/strong&gt; - customer who is the recipient of the transaction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;oldbalanceDest&lt;/strong&gt; - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;newbalanceDest&lt;/strong&gt; - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;isFraud&lt;/strong&gt; - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;isFlaggedFraud&lt;/strong&gt; - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It appears that part of our task will be to improve as much on &lt;code&gt;isFlaggedFraud&lt;/code&gt; as possible. This is ideal, as it represents a typical rules-based heuristic for identifying fraud, and this is exactly the kind of benchmark we want to show we can outperform. We'll have a look at exactly how well they did at a later point in the series.&lt;/p&gt;
&lt;p&gt;Next question: How many and what percentage of these entries are fraud?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;isFraud&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;counts&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0    6354407
1       8213
Name: isFraud, dtype: int64
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0    0.998709
1    0.001291
Name: isFraud, dtype: float64
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Herein lies the central problem: only a little over &lt;strong&gt;.1%&lt;/strong&gt; of these entries are fraudulent.&lt;/p&gt;
&lt;p&gt;In order to make this more visually apparent, we'll use the following process:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We'll take a large random sample from the dataset. I've learned from hard experience that plotting millions of points on your home laptop can take a good long while otherwise&lt;/li&gt;
&lt;li&gt;We'll drop &lt;code&gt;nameOrig&lt;/code&gt; and &lt;code&gt;nameDest&lt;/code&gt; for now. These may be useful for modeling at a later point, but they will require some transformation, and for now we just want to get a sense of scale&lt;/li&gt;
&lt;li&gt;We'll transform the &lt;code&gt;type&lt;/code&gt; column into numeric dummy variables, so as to be able to include this information in our modeling&lt;/li&gt;
&lt;li&gt;We'll reduce the dataset into two dimensions using Principal Component Analysis for plotting&lt;/li&gt;
&lt;li&gt;We'll create a scatterplot of the reduced data, colored by fraudulent vs legitimate transactions&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Take random sample of dataset&lt;/span&gt;
&lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Check to make sure that the sample is representative in terms of class ratio&lt;/span&gt;
&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isFraud&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0    9981
1      19
Name: isFraud, dtype: int64
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create a function to select and process features&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_features&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Selects and prepares features for plotting and modeling&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;        df (DataFrame): Unprocessed fraud data&lt;/span&gt;
&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;span class="sd"&gt;        df (DataFrame): Processed fraud data&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;selected_cols&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;amount&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;oldbalanceOrg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;newbalanceOrig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;oldbalanceDest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;newbalanceDest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;isFraud&amp;#39;&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;selected_cols&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;dummies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_dummies&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dummies&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create a function to perform PCA on the features and return a DataFrame for plotting&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reduce_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pca_df&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Returns features for plotting proportion of fraud&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;        df (DataFrame): Synthetic fraud database&lt;/span&gt;
&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;span class="sd"&gt;        plot_df (DataFrame): DataFrame with two principal components and target variable&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;pca_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;isFraud&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;scaler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;pca_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pca_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_components&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;components&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pca_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;comp_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;components&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plot_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;comp_df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;plot_df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plot_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Index([&amp;#39;X&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;isFraud&amp;#39;], dtype=&amp;#39;object&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create a function for plotting&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fraud_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot_df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maj_alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Plots reduced data&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;        plot_df (DataFrame): Reduced data&lt;/span&gt;
&lt;span class="sd"&gt;        maj_alpha (float): Transparency setting for majority class&lt;/span&gt;
&lt;span class="sd"&gt;        min_alpha (float): Transparency setting for minority class&lt;/span&gt;
&lt;span class="sd"&gt;        save (str): Filename for saving plot&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatterplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;maj_alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;plot_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isFraud&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Legitimate&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatterplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;min_alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot_df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;plot_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isFraud&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Fraud&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Legitimate vs Fraudulent Purchases&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tight_layout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Produce the plot!&lt;/span&gt;
&lt;span class="n"&gt;processed_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_features&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plot_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reduce_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;processed_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fraud_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/home/calre/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.
  return self.partial_fit(X, y)
/home/calre/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.
  return self.fit(X, **fit_params).transform(X)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/fraud_pca_1.png"&gt;&lt;/p&gt;
&lt;p&gt;There we go! The fraudulent entries are fairly well clustered, but they are very similar to many legitimate entries, and are completely dwarfed in number.&lt;/p&gt;
&lt;p&gt;Having built these functions, we should now be able to visualize the changes we make to the distribution of our dataset as we move ahead into resampling.&lt;/p&gt;
&lt;h1&gt;Resampling Techniques&lt;/h1&gt;
&lt;p&gt;As we've seen, one of the central challenges in fraud detection is that cases of fraud are incredibly rare in comparison to legitimate transactions. This makes training a machine learning model challenging, because it means that if 1% of all transactions are fraudulent (this is still unrealistically high), the model would be able to achieve 99% accuracy simply by guessing that every single transaction is legitimate. Not what we want! This situation where there is much more of one class than another is called an &lt;strong&gt;imbalanced class problem.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The way we deal with imbalanced classes is through &lt;strong&gt;resampling,&lt;/strong&gt; which covers an array of techniques for making the ratio of classes more equitable. These techniques may be broadly separated into three categories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Random Under-Sampling (RUS):&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Take a random sample of the majority class and train the model on the sample combined with the entirety of the minority class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random Over-Sampling (ROS):&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Randomly sample from the minority class &lt;em&gt;with replacement&lt;/em&gt; until the sizes of both classes match&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synthetic Minority Over-sampling Technique (SMOTE):&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Creating new synthetic data for the minority class using K-Nearest Neighbors to create new minority cases that are representative but not exact duplicates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;How to choose? &lt;strong&gt;RUS&lt;/strong&gt; may be appropriate when there is a large enough population of the minority class that a representative sample of the majority class will make the class sizes equitable. RUS may be a good option in our case, as given our majority class size of 6354407 and minority class size of 8213, a sample size of 9589 for the majority class would give us a representative sample with a confidence of 95% and a margin of error of 1%.&lt;/p&gt;
&lt;p&gt;For over-sampling techniques, given that our cases of fraud are similar enough to each other that KNN might produce good representative data, &lt;strong&gt;SMOTE&lt;/strong&gt; could also produce good results. If our fraud cases were more spread out, creating synthetic data using KNN could produce wildly unrepresentative noise, throwing the model off.&lt;/p&gt;
&lt;p&gt;If there is a situation where &lt;strong&gt;ROS&lt;/strong&gt; would be preferable to both RUS and SMOTE, I'm not sure what that is! Training the model on duplicate data is a huge drawback, and could lead to serious overfitting on very specific data points.&lt;/p&gt;
&lt;p&gt;In our case, as both &lt;strong&gt;RUS&lt;/strong&gt; and &lt;strong&gt;SMOTE&lt;/strong&gt; are solid options, we will try them both.&lt;/p&gt;
&lt;h2&gt;Random Under-Sampling&lt;/h2&gt;
&lt;p&gt;Both of our resampling strategies are implemented in the &lt;code&gt;imblearn&lt;/code&gt; library. The documentation may be found &lt;a href="https://imbalanced-learn.readthedocs.io/en/stable/index.html"&gt;by clicking here&lt;/a&gt;. I'll explain the parameters we'll be using as we go along.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;imblearn.under_sampling&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomUnderSampler&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;RandomUnderSampler&lt;/code&gt; does exactly what it says on the tin. The important parameter we need to tweak is called &lt;code&gt;sampling_strategy&lt;/code&gt;. If you don't touch this setting, &lt;code&gt;RandomUnderSampler&lt;/code&gt; will simply make the sizes of the larger classes match the size of the smallest class through random sampling without replacement. However, we want to make sure that we have a representative sample for the majority class, and using &lt;a href="https://www.qualtrics.com/blog/calculating-sample-size/"&gt;this calculator&lt;/a&gt; while asking for a 95% Confidence Level with a 1% Margin of Error suggests a slightly larger sample size of 9589.&lt;/p&gt;
&lt;p&gt;Fortunately &lt;code&gt;sampling_strategy&lt;/code&gt; can optionally take a dictionary, where the keys are class names, and the values are sample sizes. This allows us to set the exact sample size we want for the majority class.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Instantiate RandomUnderSampler&lt;/span&gt;
&lt;span class="n"&gt;RUS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomUnderSampler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sampling_strategy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;9589&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create a function for use with any resampling method&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;resample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Resamples df using method with .fit_resample()&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;        df (DataFrame): Fraud data&lt;/span&gt;
&lt;span class="sd"&gt;        method (object): Resampler with .fit_resample() method&lt;/span&gt;
&lt;span class="sd"&gt;    Retuns:&lt;/span&gt;
&lt;span class="sd"&gt;        resampled_df (DataFrame): Resampled DataFrame&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;processed_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_features&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;processed_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;isFraud&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;processed_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;processed_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_resample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;processed_df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;cols&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;processed_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;isFraud&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;pdf_x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;processed_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;processed_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pdf_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;processed_y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;isFraud&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;resampled_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;pdf_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pdf_y&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;resampled_df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Apply RandomUnderSampler to data&lt;/span&gt;
&lt;span class="n"&gt;rus_resampled&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;resample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RUS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rus_resampled&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rus_resampled&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isFraud&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(17802, 11)
0    9589
1    8213
Name: isFraud, dtype: int64
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;fraud_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reduce_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rus_resampled&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;min_alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/fraud_pca_2.png"&gt;&lt;/p&gt;
&lt;p&gt;The result of our work is a nicely balanced dataset, using all real data and a representative random sample of the majority class.&lt;/p&gt;
&lt;p&gt;Let's wrap up by applying SMOTE, which should be a snap given that we've already prepared the major groundwork using the functions we've written to this point.&lt;/p&gt;
&lt;h2&gt;SMOTE&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;imblearn.over_sampling&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SMOTE&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Instantiate SMOTE&lt;/span&gt;
&lt;span class="n"&gt;SM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SMOTE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Use our helpful resampling function&lt;/span&gt;
&lt;span class="n"&gt;sm_resampled&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;resample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;SM&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sm_resampled&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sm_resampled&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isFraud&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(12708814, 11)
1    6354407
0    6354407
Name: isFraud, dtype: int64
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Take random sample for easier plotting&lt;/span&gt;
&lt;span class="n"&gt;sm_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm_resampled&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Produce the plot!&lt;/span&gt;
&lt;span class="n"&gt;fraud_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reduce_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sm_sample&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;min_alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/fraud_pca_3.png"&gt;&lt;/p&gt;
&lt;p&gt;Again, we have a well balanced dataset. This dataset is much larger than the one produced by RUS, but contains a lot of synthetic data points. Because our original fraudulent data was so closely clustered, this hopefully shouldn't compromise the quality of our predictions. Notice that our plot is visually quite similar to the one produced by RUS.&lt;/p&gt;
&lt;h1&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;That's enough for our first foray into the fundamentals of fraud detection in Python! To wrap up, here are the major takeaways in condensed form:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fraud is damaging, but it is also &lt;strong&gt;very rare.&lt;/strong&gt; This is the central challenge for modeling fraud&lt;/li&gt;
&lt;li&gt;A dataset where one class of interest is wildly outnumbered by other classes is said to be &lt;strong&gt;imbalanced&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;It is useful to have visual strategies to get a sense for the scope of class imbalance in a dataset. We've learned to use &lt;strong&gt;PCA and scatterplots&lt;/strong&gt; in order to visualize these relationships&lt;/li&gt;
&lt;li&gt;In order to prepare an imbalanced dataset for modeling, we need to apply &lt;strong&gt;resampling strategies&lt;/strong&gt; to make the class balance more equitable. We learned about &lt;strong&gt;Random Under-Sampling (RUS)&lt;/strong&gt; of the majority class, &lt;strong&gt;Random Over-Sampling (ROS)&lt;/strong&gt; of the minority class, and &lt;strong&gt;Synthetic Minority Over-sampling Technique (SMOTE)&lt;/strong&gt; for generating new representative minority class data&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the next part of our deep dive, we'll cover common machine learning techniques for modeling fraud, and how to use them in pipelines with Scikit-Learn. Thanks for reading, and stay tuned!&lt;/p&gt;</content></entry><entry><title>Heatmap Color Labels in Seaborn</title><link href="/heatmap-color-labels-in-seaborn.html" rel="alternate"></link><published>2019-04-05T00:00:00-04:00</published><updated>2019-04-05T00:00:00-04:00</updated><author><name>Chris Remmel</name></author><id>tag:None,2019-04-05:/heatmap-color-labels-in-seaborn.html</id><summary type="html">&lt;h1&gt;Multiple Layers of Color Labels in Seaborn Heatmaps&lt;/h1&gt;
&lt;p&gt;I'm currently working with biological test data, which by its nature tends to have a large number of features. This presents all sorts of challenges, not least of which is the difficulty in interpreting correlation heatmaps when there are so many rows …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Multiple Layers of Color Labels in Seaborn Heatmaps&lt;/h1&gt;
&lt;p&gt;I'm currently working with biological test data, which by its nature tends to have a large number of features. This presents all sorts of challenges, not least of which is the difficulty in interpreting correlation heatmaps when there are so many rows and columns that the labels become impossible to read!&lt;/p&gt;
&lt;p&gt;One solution to this problem is to group the features into categories, assign each category a color, and annotate the rows and columns of a heatmap. For a toy example of this using a more manageable non-biological dataset, consider the following:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Heatmap One" src="/images/heatmap_one.png"&gt;&lt;/p&gt;
&lt;p&gt;This is a nice way to interpret the correlation heatmap of a large dataset, as the column and row colors allow you to identify useful clusters by sight. What if, however, each feature has not just one useful attribute for grouping, but two? For those working in life sciences, you might take the example of wanting to be able to know both reagent and antigen by sight.&lt;/p&gt;
&lt;p&gt;Fortunately, seaborn makes this easy as well. Let's work through an example using the Residential Building Data Set from the UCI Machine Learning Library.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_excel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data/raw/Residential-Building-Data-Set.xlsx&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;PROJECT DATES (PERSIAN CALENDAR)&lt;/th&gt;
      &lt;th&gt;Unnamed: 1&lt;/th&gt;
      &lt;th&gt;Unnamed: 2&lt;/th&gt;
      &lt;th&gt;Unnamed: 3&lt;/th&gt;
      &lt;th&gt;PROJECT PHYSICAL AND FINANCIAL VARIABLES&lt;/th&gt;
      &lt;th&gt;Unnamed: 5&lt;/th&gt;
      &lt;th&gt;Unnamed: 6&lt;/th&gt;
      &lt;th&gt;Unnamed: 7&lt;/th&gt;
      &lt;th&gt;Unnamed: 8&lt;/th&gt;
      &lt;th&gt;Unnamed: 9&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Unnamed: 99&lt;/th&gt;
      &lt;th&gt;Unnamed: 100&lt;/th&gt;
      &lt;th&gt;Unnamed: 101&lt;/th&gt;
      &lt;th&gt;Unnamed: 102&lt;/th&gt;
      &lt;th&gt;Unnamed: 103&lt;/th&gt;
      &lt;th&gt;Unnamed: 104&lt;/th&gt;
      &lt;th&gt;Unnamed: 105&lt;/th&gt;
      &lt;th&gt;Unnamed: 106&lt;/th&gt;
      &lt;th&gt;OUTPUTS&lt;/th&gt;
      &lt;th&gt;Unnamed: 108&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;START YEAR&lt;/td&gt;
      &lt;td&gt;START QUARTER&lt;/td&gt;
      &lt;td&gt;COMPLETION YEAR&lt;/td&gt;
      &lt;td&gt;COMPLETION QUARTER&lt;/td&gt;
      &lt;td&gt;V-1&lt;/td&gt;
      &lt;td&gt;V-2&lt;/td&gt;
      &lt;td&gt;V-3&lt;/td&gt;
      &lt;td&gt;V-4&lt;/td&gt;
      &lt;td&gt;V-5&lt;/td&gt;
      &lt;td&gt;V-6&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;V-22&lt;/td&gt;
      &lt;td&gt;V-23&lt;/td&gt;
      &lt;td&gt;V-24&lt;/td&gt;
      &lt;td&gt;V-25&lt;/td&gt;
      &lt;td&gt;V-26&lt;/td&gt;
      &lt;td&gt;V-27&lt;/td&gt;
      &lt;td&gt;V-28&lt;/td&gt;
      &lt;td&gt;V-29&lt;/td&gt;
      &lt;td&gt;V-9&lt;/td&gt;
      &lt;td&gt;V-10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3150&lt;/td&gt;
      &lt;td&gt;920&lt;/td&gt;
      &lt;td&gt;598.5&lt;/td&gt;
      &lt;td&gt;190&lt;/td&gt;
      &lt;td&gt;1010.84&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;815.5&lt;/td&gt;
      &lt;td&gt;1755&lt;/td&gt;
      &lt;td&gt;8002&lt;/td&gt;
      &lt;td&gt;60.74&lt;/td&gt;
      &lt;td&gt;54.26&lt;/td&gt;
      &lt;td&gt;2978.26&lt;/td&gt;
      &lt;td&gt;41407&lt;/td&gt;
      &lt;td&gt;601988&lt;/td&gt;
      &lt;td&gt;2200&lt;/td&gt;
      &lt;td&gt;410&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;84&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;89&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;7600&lt;/td&gt;
      &lt;td&gt;1140&lt;/td&gt;
      &lt;td&gt;3040&lt;/td&gt;
      &lt;td&gt;400&lt;/td&gt;
      &lt;td&gt;963.81&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1316.3&lt;/td&gt;
      &lt;td&gt;8364.78&lt;/td&gt;
      &lt;td&gt;8393&lt;/td&gt;
      &lt;td&gt;90.95&lt;/td&gt;
      &lt;td&gt;89.79&lt;/td&gt;
      &lt;td&gt;11379.4&lt;/td&gt;
      &lt;td&gt;44835&lt;/td&gt;
      &lt;td&gt;929027&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;1000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;78&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4800&lt;/td&gt;
      &lt;td&gt;840&lt;/td&gt;
      &lt;td&gt;480&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;689.84&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;765.8&lt;/td&gt;
      &lt;td&gt;1755&lt;/td&gt;
      &lt;td&gt;4930&lt;/td&gt;
      &lt;td&gt;38.7&lt;/td&gt;
      &lt;td&gt;32.04&lt;/td&gt;
      &lt;td&gt;1653.06&lt;/td&gt;
      &lt;td&gt;37933&lt;/td&gt;
      &lt;td&gt;377829&lt;/td&gt;
      &lt;td&gt;1200&lt;/td&gt;
      &lt;td&gt;170&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;72&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;685&lt;/td&gt;
      &lt;td&gt;202&lt;/td&gt;
      &lt;td&gt;13.7&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;459.54&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;152.25&lt;/td&gt;
      &lt;td&gt;1442.31&lt;/td&gt;
      &lt;td&gt;1456&lt;/td&gt;
      &lt;td&gt;9.73&lt;/td&gt;
      &lt;td&gt;8.34&lt;/td&gt;
      &lt;td&gt;686.16&lt;/td&gt;
      &lt;td&gt;8194&lt;/td&gt;
      &lt;td&gt;122032&lt;/td&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 109 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;This dataset contains measurements relating to real estate construction projects in Iran. Broadly speaking, these measurements can be grouped into &lt;strong&gt;physical and financial (P&amp;amp;F)&lt;/strong&gt; measurements which were recorded once, and &lt;strong&gt;economic (E)&lt;/strong&gt; measurements which were recorded at five time points throughout the contruction project. For more information on the features, you may check out the data dictionary here:&lt;/p&gt;
&lt;p&gt;First, we'll clean the data so that it contains only the P&amp;amp;F measurements and the E measurements at the final timepoint, converted into the appropriate data type.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Use the first row as the columns&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,:]&lt;/span&gt;
&lt;span class="c1"&gt;# Select only the P&amp;amp;F features, and the E features for one timepoint&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;:]],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Reorder the columns so that they are in ascending numerical order&lt;/span&gt;
&lt;span class="n"&gt;col_order&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;V-&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;col_order&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# Drop the extra row of column names and reset the index numbering&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Convert the DataFrame to numeric&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_numeric&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;V-1&lt;/th&gt;
      &lt;th&gt;V-2&lt;/th&gt;
      &lt;th&gt;V-3&lt;/th&gt;
      &lt;th&gt;V-4&lt;/th&gt;
      &lt;th&gt;V-5&lt;/th&gt;
      &lt;th&gt;V-6&lt;/th&gt;
      &lt;th&gt;V-7&lt;/th&gt;
      &lt;th&gt;V-8&lt;/th&gt;
      &lt;th&gt;V-9&lt;/th&gt;
      &lt;th&gt;V-10&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;V-20&lt;/th&gt;
      &lt;th&gt;V-21&lt;/th&gt;
      &lt;th&gt;V-22&lt;/th&gt;
      &lt;th&gt;V-23&lt;/th&gt;
      &lt;th&gt;V-24&lt;/th&gt;
      &lt;th&gt;V-25&lt;/th&gt;
      &lt;th&gt;V-26&lt;/th&gt;
      &lt;th&gt;V-27&lt;/th&gt;
      &lt;th&gt;V-28&lt;/th&gt;
      &lt;th&gt;V-29&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;3150.0&lt;/td&gt;
      &lt;td&gt;920.0&lt;/td&gt;
      &lt;td&gt;598.5&lt;/td&gt;
      &lt;td&gt;190.0&lt;/td&gt;
      &lt;td&gt;1010.84&lt;/td&gt;
      &lt;td&gt;16.0&lt;/td&gt;
      &lt;td&gt;1200.0&lt;/td&gt;
      &lt;td&gt;2200.0&lt;/td&gt;
      &lt;td&gt;410.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;733.800000&lt;/td&gt;
      &lt;td&gt;815.50&lt;/td&gt;
      &lt;td&gt;1755.00&lt;/td&gt;
      &lt;td&gt;8002.0&lt;/td&gt;
      &lt;td&gt;60.74&lt;/td&gt;
      &lt;td&gt;54.26&lt;/td&gt;
      &lt;td&gt;2978.26&lt;/td&gt;
      &lt;td&gt;41407.0&lt;/td&gt;
      &lt;td&gt;601988.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;7600.0&lt;/td&gt;
      &lt;td&gt;1140.0&lt;/td&gt;
      &lt;td&gt;3040.0&lt;/td&gt;
      &lt;td&gt;400.0&lt;/td&gt;
      &lt;td&gt;963.81&lt;/td&gt;
      &lt;td&gt;23.0&lt;/td&gt;
      &lt;td&gt;2900.0&lt;/td&gt;
      &lt;td&gt;5000.0&lt;/td&gt;
      &lt;td&gt;1000.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;1143.800000&lt;/td&gt;
      &lt;td&gt;1316.30&lt;/td&gt;
      &lt;td&gt;8364.78&lt;/td&gt;
      &lt;td&gt;8393.0&lt;/td&gt;
      &lt;td&gt;90.95&lt;/td&gt;
      &lt;td&gt;89.79&lt;/td&gt;
      &lt;td&gt;11379.37&lt;/td&gt;
      &lt;td&gt;44835.0&lt;/td&gt;
      &lt;td&gt;929027.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;4800.0&lt;/td&gt;
      &lt;td&gt;840.0&lt;/td&gt;
      &lt;td&gt;480.0&lt;/td&gt;
      &lt;td&gt;100.0&lt;/td&gt;
      &lt;td&gt;689.84&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;630.0&lt;/td&gt;
      &lt;td&gt;1200.0&lt;/td&gt;
      &lt;td&gt;170.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;589.500000&lt;/td&gt;
      &lt;td&gt;765.80&lt;/td&gt;
      &lt;td&gt;1755.00&lt;/td&gt;
      &lt;td&gt;4930.0&lt;/td&gt;
      &lt;td&gt;38.70&lt;/td&gt;
      &lt;td&gt;32.04&lt;/td&gt;
      &lt;td&gt;1653.06&lt;/td&gt;
      &lt;td&gt;37933.0&lt;/td&gt;
      &lt;td&gt;377828.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;685.0&lt;/td&gt;
      &lt;td&gt;202.0&lt;/td&gt;
      &lt;td&gt;13.7&lt;/td&gt;
      &lt;td&gt;20.0&lt;/td&gt;
      &lt;td&gt;459.54&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;140.0&lt;/td&gt;
      &lt;td&gt;165.0&lt;/td&gt;
      &lt;td&gt;30.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12.0&lt;/td&gt;
      &lt;td&gt;197.679557&lt;/td&gt;
      &lt;td&gt;152.25&lt;/td&gt;
      &lt;td&gt;1442.31&lt;/td&gt;
      &lt;td&gt;1456.0&lt;/td&gt;
      &lt;td&gt;9.73&lt;/td&gt;
      &lt;td&gt;8.34&lt;/td&gt;
      &lt;td&gt;686.16&lt;/td&gt;
      &lt;td&gt;8194.0&lt;/td&gt;
      &lt;td&gt;122031.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;3000.0&lt;/td&gt;
      &lt;td&gt;800.0&lt;/td&gt;
      &lt;td&gt;1230.0&lt;/td&gt;
      &lt;td&gt;410.0&lt;/td&gt;
      &lt;td&gt;631.91&lt;/td&gt;
      &lt;td&gt;13.0&lt;/td&gt;
      &lt;td&gt;5000.0&lt;/td&gt;
      &lt;td&gt;5500.0&lt;/td&gt;
      &lt;td&gt;700.0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;14.0&lt;/td&gt;
      &lt;td&gt;2220.600000&lt;/td&gt;
      &lt;td&gt;2244.10&lt;/td&gt;
      &lt;td&gt;9231.76&lt;/td&gt;
      &lt;td&gt;9286.0&lt;/td&gt;
      &lt;td&gt;136.60&lt;/td&gt;
      &lt;td&gt;140.20&lt;/td&gt;
      &lt;td&gt;9821.00&lt;/td&gt;
      &lt;td&gt;48260.0&lt;/td&gt;
      &lt;td&gt;1734973.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 29 columns&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Excellent. We now have useable data for generating clustered correlation heatmaps. If we do that now, we get the following result:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clustermap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bwr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;seaborn.matrix.ClusterGrid at 0x7fd12bb00278&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="images/output_9_1.png"&gt;&lt;/p&gt;
&lt;p&gt;There are some strong patterns here, but the labels aren't very useful. It would be nice to see if these are grouped by our categories of features, P&amp;amp;F and E.&lt;/p&gt;
&lt;p&gt;In order to accomplish this, we first take our list of columns and split them into their respective groups.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;physical_financial&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;col_order&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;economic&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;col_order&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we will need some colors. Seaborn makes this easy through the &lt;code&gt;color_palette()&lt;/code&gt; function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;palette&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;color_palette&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;palette&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[(0.12156862745098039, 0.4666666666666667, 0.7058823529411765),
 (1.0, 0.4980392156862745, 0.054901960784313725),
 (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),
 (0.8392156862745098, 0.15294117647058825, 0.1568627450980392),
 (0.5803921568627451, 0.403921568627451, 0.7411764705882353),
 (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),
 (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),
 (0.4980392156862745, 0.4980392156862745, 0.4980392156862745),
 (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),
 (0.09019607843137255, 0.7450980392156863, 0.8117647058823529)]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To see what these colors look like, seaborn offers the useful &lt;code&gt;palplot()&lt;/code&gt; function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;palplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_15_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Very nice! In order to assign these colors to categories, seaborn will want a Series with the colors as values, and the associated features as index labels. Let's create that.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create dictionary with features as keys and colors as values&lt;/span&gt;
&lt;span class="n"&gt;color_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;physical_financial&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;color_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;color_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# Convert the dictionary into a Series&lt;/span&gt;
&lt;span class="n"&gt;color_rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;color_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;color_rows&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;V-1    (0.12156862745098039, 0.4666666666666667, 0.70...
V-2    (0.12156862745098039, 0.4666666666666667, 0.70...
V-3    (0.12156862745098039, 0.4666666666666667, 0.70...
V-4    (0.12156862745098039, 0.4666666666666667, 0.70...
V-5    (0.12156862745098039, 0.4666666666666667, 0.70...
dtype: object
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In order to assign this color mapping to the clustered heatmap, we simply assign it to the &lt;code&gt;row_colors&lt;/code&gt; and &lt;code&gt;col_colors&lt;/code&gt; optional arguments.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clustermap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bwr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row_colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;color_rows&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;col_colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;color_rows&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;seaborn.matrix.ClusterGrid at 0x7fd12b254080&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_19_1.png"&gt;&lt;/p&gt;
&lt;p&gt;Very nice. Now, let's add a second layer. We might also want to know at sight what kind measurement each feature contains. Let's have a look at the data dictionary in order to determine this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Load the data dictionary in the second page of the Excel file&lt;/span&gt;
&lt;span class="n"&gt;desc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_excel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data/raw/Residential-Building-Data-Set.xlsx&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sheet_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Variable Group&lt;/th&gt;
      &lt;th&gt;Variable ID&lt;/th&gt;
      &lt;th&gt;Descriptions&lt;/th&gt;
      &lt;th&gt;Unit&lt;/th&gt;
      &lt;th&gt;Time Lag Number p&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;PROJECT PHYSICAL AND FINANCIAL VARIABLES&lt;/td&gt;
      &lt;td&gt;V-1&lt;/td&gt;
      &lt;td&gt;Project locality defined in terms of zip codes&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;V-2&lt;/td&gt;
      &lt;td&gt;Total floor area of the building&lt;/td&gt;
      &lt;td&gt;m2&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;V-3&lt;/td&gt;
      &lt;td&gt;Lot area&lt;/td&gt;
      &lt;td&gt;m2&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;V-4&lt;/td&gt;
      &lt;td&gt;Total preliminary estimated construction cost ...&lt;/td&gt;
      &lt;td&gt;10000000 IRRm&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;V-5&lt;/td&gt;
      &lt;td&gt;Preliminary estimated construction cost based ...&lt;/td&gt;
      &lt;td&gt;10000 IRRm&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Convert the Unit column to string type so that we can get unique values&lt;/span&gt;
&lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Unit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Get unique unit types&lt;/span&gt;
&lt;span class="n"&gt;units&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;units&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([&amp;#39;nan&amp;#39;, &amp;#39;m2 &amp;#39;, &amp;#39;10000000 IRRm &amp;#39;, &amp;#39;10000 IRRm &amp;#39;,
       &amp;#39;As a number of time resolution e &amp;#39;, &amp;#39;10000 IRRm&amp;#39;, &amp;#39;m2&amp;#39;,
       &amp;#39;10000000 IRRm&amp;#39;, &amp;#39;%&amp;#39;, &amp;#39;10000 IRRm /m2&amp;#39;, &amp;#39;IRRm&amp;#39;], dtype=object)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It seems as though we measurements in currency (IRRm), in area (m2), and some other miscellaneous types of measures. Let's make a new mapping using the same pattern.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;unitmap&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;unit&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;units&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;IRRm&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;unit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;unitmap&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;unit&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;m2&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;unit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;unitmap&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;unit&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;unitmap&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;unit&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;unitmap&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Variable ID  &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Unit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Variable ID&lt;/th&gt;
      &lt;th&gt;Unit&lt;/th&gt;
      &lt;th&gt;Color&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;V-1&lt;/td&gt;
      &lt;td&gt;nan&lt;/td&gt;
      &lt;td&gt;(0.5803921568627451, 0.403921568627451, 0.7411...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;V-2&lt;/td&gt;
      &lt;td&gt;m2&lt;/td&gt;
      &lt;td&gt;(0.8392156862745098, 0.15294117647058825, 0.15...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;V-3&lt;/td&gt;
      &lt;td&gt;m2&lt;/td&gt;
      &lt;td&gt;(0.8392156862745098, 0.15294117647058825, 0.15...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;V-4&lt;/td&gt;
      &lt;td&gt;10000000 IRRm&lt;/td&gt;
      &lt;td&gt;(0.17254901960784313, 0.6274509803921569, 0.17...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;V-5&lt;/td&gt;
      &lt;td&gt;10000 IRRm&lt;/td&gt;
      &lt;td&gt;(0.17254901960784313, 0.6274509803921569, 0.17...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Delete extraneous row at end of dictionary&lt;/span&gt;
&lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;29&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Get only features and colors for mapping&lt;/span&gt;
&lt;span class="n"&gt;color_rows_two&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;desc&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Variable ID  &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="c1"&gt;# Set features as index&lt;/span&gt;
&lt;span class="n"&gt;color_rows_two&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;color_rows_two&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Variable ID  &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Delete the index name for cleanliness&lt;/span&gt;
&lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;color_rows_two&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="c1"&gt;# Use iloc to convert DataFrame into Series&lt;/span&gt;
&lt;span class="n"&gt;color_rows_two&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;color_rows_two&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;color_rows_two&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;V-1    (0.5803921568627451, 0.403921568627451, 0.7411...
V-2    (0.8392156862745098, 0.15294117647058825, 0.15...
V-3    (0.8392156862745098, 0.15294117647058825, 0.15...
V-4    (0.17254901960784313, 0.6274509803921569, 0.17...
V-5    (0.17254901960784313, 0.6274509803921569, 0.17...
Name: Color, dtype: object
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Having completed all this, we simple pass both Series into &lt;code&gt;row_colors&lt;/code&gt; and &lt;code&gt;col_colors&lt;/code&gt; as a list. It is that simple.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clustermap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bwr&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row_colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;color_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color_rows_two&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;col_colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;color_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color_rows_two&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;seaborn.matrix.ClusterGrid at 0x7fd12a929588&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_30_1.png"&gt;&lt;/p&gt;
&lt;p&gt;Voila! Two layers of row and column colors, for easy interpretation of feature clusters by groups.&lt;/p&gt;
&lt;p&gt;In my next post, I'll cover how to make custom legends for these color labels using matplotlib. Thanks for reading, and stay tuned!&lt;/p&gt;</content></entry><entry><title>Project Write-Up: Predicting the Diabetes Belt</title><link href="/predicting-the-diabetes-belt.html" rel="alternate"></link><published>2019-02-15T00:00:00-05:00</published><updated>2019-02-15T00:00:00-05:00</updated><author><name>Chris Remmel</name></author><id>tag:None,2019-02-15:/predicting-the-diabetes-belt.html</id><summary type="html">&lt;h3&gt;Building a Binary Classifier using the USDA's Food Atlas&lt;/h3&gt;
&lt;h1&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#obtaining"&gt;Obtaining Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#scrubbing"&gt;Scrubbing Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#exploratory"&gt;Exploratory Data Analysis&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#feature"&gt;Feature Ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#further"&gt;Further Exploration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#building"&gt;Building a Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wrap"&gt;Wrap-Up&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#recommendations"&gt;Recommendations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#possible"&gt;Possible Next Steps&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Introduction&lt;a name="introduction"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;In this project, I used data on food access from the USDA's Food Environment Atlas to predict …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Building a Binary Classifier using the USDA's Food Atlas&lt;/h3&gt;
&lt;h1&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#obtaining"&gt;Obtaining Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#scrubbing"&gt;Scrubbing Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#exploratory"&gt;Exploratory Data Analysis&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#feature"&gt;Feature Ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#further"&gt;Further Exploration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#building"&gt;Building a Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wrap"&gt;Wrap-Up&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#recommendations"&gt;Recommendations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#possible"&gt;Possible Next Steps&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Introduction&lt;a name="introduction"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;In this project, I used data on food access from the USDA's Food Environment Atlas to predict whether each US county would qualify as a part of the Diabetes Belt, which is a area in the southwest of United States where the rate of adult type II diabetes is especially high. I conceived of this project as an opportunity to practice creating a machine learning classifier on a topic of social relevance.&lt;/p&gt;
&lt;p&gt;In order to qualify as a part of the Diabetes Belt, a US County must have an adult diabetes rate of 11% or higher. The CDC made this designation based off of data from 2008. I will be attempting to predict the counties that would be a part of the belt in 2013, which is the most recent publicly downloadable data on adult diabetes.&lt;/p&gt;
&lt;h1&gt;Obtaining Data&lt;a name="obtaining"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The data is fortunately available in a single Excel file on the USDA's website:&lt;/p&gt;
&lt;p&gt;https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads/&lt;/p&gt;
&lt;p&gt;Different categories of data are distributed across six different sheets, but as each row is a US county with an unique FIPS code, it was simple to combine into a single pandas DataFrame.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;excel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ExcelFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sheets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;excel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sheet_names&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

    &lt;span class="n"&gt;dataframes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;excel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sheet_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sheet&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sheet&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sheets&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;reduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;FIPS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dataframes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;food_atlas.xls&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(3143, 296)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;FIPS&lt;/th&gt;
      &lt;th&gt;State_x&lt;/th&gt;
      &lt;th&gt;County_x&lt;/th&gt;
      &lt;th&gt;LACCESS_POP10&lt;/th&gt;
      &lt;th&gt;LACCESS_POP15&lt;/th&gt;
      &lt;th&gt;PCH_LACCESS_POP_10_15&lt;/th&gt;
      &lt;th&gt;PCT_LACCESS_POP10&lt;/th&gt;
      &lt;th&gt;PCT_LACCESS_POP15&lt;/th&gt;
      &lt;th&gt;LACCESS_LOWI10&lt;/th&gt;
      &lt;th&gt;LACCESS_LOWI15&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;PCT_NHPI10&lt;/th&gt;
      &lt;th&gt;PCT_65OLDER10&lt;/th&gt;
      &lt;th&gt;PCT_18YOUNGER10&lt;/th&gt;
      &lt;th&gt;MEDHHINC15&lt;/th&gt;
      &lt;th&gt;POVRATE15&lt;/th&gt;
      &lt;th&gt;PERPOV10&lt;/th&gt;
      &lt;th&gt;CHILDPOVRATE15&lt;/th&gt;
      &lt;th&gt;PERCHLDPOV10&lt;/th&gt;
      &lt;th&gt;METRO13&lt;/th&gt;
      &lt;th&gt;POPLOSS10&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1001&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;Autauga&lt;/td&gt;
      &lt;td&gt;18428.439685&lt;/td&gt;
      &lt;td&gt;17496.693038&lt;/td&gt;
      &lt;td&gt;-5.056026&lt;/td&gt;
      &lt;td&gt;33.769657&lt;/td&gt;
      &lt;td&gt;32.062255&lt;/td&gt;
      &lt;td&gt;5344.427472&lt;/td&gt;
      &lt;td&gt;6543.676824&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.040314&lt;/td&gt;
      &lt;td&gt;11.995382&lt;/td&gt;
      &lt;td&gt;26.777959&lt;/td&gt;
      &lt;td&gt;56580.0&lt;/td&gt;
      &lt;td&gt;12.7&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;18.8&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1003&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;Baldwin&lt;/td&gt;
      &lt;td&gt;35210.814078&lt;/td&gt;
      &lt;td&gt;30561.264430&lt;/td&gt;
      &lt;td&gt;-13.204891&lt;/td&gt;
      &lt;td&gt;19.318473&lt;/td&gt;
      &lt;td&gt;16.767489&lt;/td&gt;
      &lt;td&gt;9952.144027&lt;/td&gt;
      &lt;td&gt;9886.831137&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.043343&lt;/td&gt;
      &lt;td&gt;16.771185&lt;/td&gt;
      &lt;td&gt;22.987408&lt;/td&gt;
      &lt;td&gt;52387.0&lt;/td&gt;
      &lt;td&gt;12.9&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;19.6&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1005&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;Barbour&lt;/td&gt;
      &lt;td&gt;5722.305602&lt;/td&gt;
      &lt;td&gt;6069.523628&lt;/td&gt;
      &lt;td&gt;6.067799&lt;/td&gt;
      &lt;td&gt;20.840972&lt;/td&gt;
      &lt;td&gt;22.105560&lt;/td&gt;
      &lt;td&gt;3135.676086&lt;/td&gt;
      &lt;td&gt;2948.790251&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.087409&lt;/td&gt;
      &lt;td&gt;14.236807&lt;/td&gt;
      &lt;td&gt;21.906982&lt;/td&gt;
      &lt;td&gt;31433.0&lt;/td&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;45.2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1007&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;Bibb&lt;/td&gt;
      &lt;td&gt;1044.867327&lt;/td&gt;
      &lt;td&gt;969.378841&lt;/td&gt;
      &lt;td&gt;-7.224696&lt;/td&gt;
      &lt;td&gt;4.559753&lt;/td&gt;
      &lt;td&gt;4.230324&lt;/td&gt;
      &lt;td&gt;491.449066&lt;/td&gt;
      &lt;td&gt;596.162829&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.030548&lt;/td&gt;
      &lt;td&gt;12.681650&lt;/td&gt;
      &lt;td&gt;22.696923&lt;/td&gt;
      &lt;td&gt;40767.0&lt;/td&gt;
      &lt;td&gt;22.2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;29.3&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1009&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;Blount&lt;/td&gt;
      &lt;td&gt;1548.175559&lt;/td&gt;
      &lt;td&gt;3724.428242&lt;/td&gt;
      &lt;td&gt;140.568857&lt;/td&gt;
      &lt;td&gt;2.700840&lt;/td&gt;
      &lt;td&gt;6.497380&lt;/td&gt;
      &lt;td&gt;609.027708&lt;/td&gt;
      &lt;td&gt;1650.959482&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;0.031402&lt;/td&gt;
      &lt;td&gt;14.722096&lt;/td&gt;
      &lt;td&gt;24.608353&lt;/td&gt;
      &lt;td&gt;50487.0&lt;/td&gt;
      &lt;td&gt;14.7&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;22.2&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 296 columns&lt;/p&gt;
&lt;/div&gt;

&lt;h1&gt;Scrubbing Data&lt;a name="scrubbing"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The combined DataFrame had 296 features, many of which duplicated information or had missing entries. I performed the following operations to scrub the data clean (dropped measurements in bold):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;strong&gt;State and County&lt;/strong&gt; features were not appropriate for use in the classifier, so these I dropped. I stored the FIPS codes in a separate list for graphing purposes.&lt;/li&gt;
&lt;li&gt;For every feature recorded as a &lt;strong&gt;raw count&lt;/strong&gt;, the USDA conveniently provided either a normalized or scaled version. This left me free to drop all of the raw counts.&lt;/li&gt;
&lt;li&gt;Wherever there were &lt;strong&gt;multiple years of measurements&lt;/strong&gt;, I kept only the most recent year, 2013 or prior.&lt;/li&gt;
&lt;li&gt;While features showing the &lt;strong&gt;change from one year's measurement to the next&lt;/strong&gt; could have been interesting transformed into a categorical feature (i.e. positive change, negative change, no change), for the scope of the project I elected to drop these features. It could be a fruitful area of exploration, however.&lt;/li&gt;
&lt;li&gt;Finally, I dropped all columns containing &lt;strong&gt;null values&lt;/strong&gt;. Because each row is a county, any leniency here would rob us of crucial data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After the scrubbing step, I was left with a much more manageable selection of 37 features, including the target.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;PCT_DIABETES_ADULTS13&lt;/th&gt;
      &lt;th&gt;PCT_65OLDER10&lt;/th&gt;
      &lt;th&gt;GROCPTH09&lt;/th&gt;
      &lt;th&gt;PCT_LACCESS_POP10&lt;/th&gt;
      &lt;th&gt;PCT_WIC09&lt;/th&gt;
      &lt;th&gt;PCT_SFSP09&lt;/th&gt;
      &lt;th&gt;PCT_LACCESS_HHNV10&lt;/th&gt;
      &lt;th&gt;SNAP_OAPP09&lt;/th&gt;
      &lt;th&gt;PCT_LACCESS_LOWI10&lt;/th&gt;
      &lt;th&gt;SNAPSPTH12&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;PCT_NSLP09&lt;/th&gt;
      &lt;th&gt;PCT_NHWHITE10&lt;/th&gt;
      &lt;th&gt;PCT_NHPI10&lt;/th&gt;
      &lt;th&gt;CONVSPTH09&lt;/th&gt;
      &lt;th&gt;SNAP_PART_RATE13&lt;/th&gt;
      &lt;th&gt;PCT_NHBLACK10&lt;/th&gt;
      &lt;th&gt;PCT_SBP09&lt;/th&gt;
      &lt;th&gt;SNAP_REPORTSIMPLE09&lt;/th&gt;
      &lt;th&gt;PCT_NHNA10&lt;/th&gt;
      &lt;th&gt;SNAP_CAP09&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;13.0&lt;/td&gt;
      &lt;td&gt;11.995382&lt;/td&gt;
      &lt;td&gt;0.110834&lt;/td&gt;
      &lt;td&gt;33.769657&lt;/td&gt;
      &lt;td&gt;2.990417&lt;/td&gt;
      &lt;td&gt;0.56489&lt;/td&gt;
      &lt;td&gt;3.284786&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;9.793530&lt;/td&gt;
      &lt;td&gt;0.674004&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12.315055&lt;/td&gt;
      &lt;td&gt;77.246156&lt;/td&gt;
      &lt;td&gt;0.040314&lt;/td&gt;
      &lt;td&gt;0.535698&lt;/td&gt;
      &lt;td&gt;89.184&lt;/td&gt;
      &lt;td&gt;17.582599&lt;/td&gt;
      &lt;td&gt;4.509008&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.397647&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;10.4&lt;/td&gt;
      &lt;td&gt;16.771185&lt;/td&gt;
      &lt;td&gt;0.133775&lt;/td&gt;
      &lt;td&gt;19.318473&lt;/td&gt;
      &lt;td&gt;2.990417&lt;/td&gt;
      &lt;td&gt;0.56489&lt;/td&gt;
      &lt;td&gt;2.147827&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;5.460261&lt;/td&gt;
      &lt;td&gt;0.725055&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12.315055&lt;/td&gt;
      &lt;td&gt;83.504787&lt;/td&gt;
      &lt;td&gt;0.043343&lt;/td&gt;
      &lt;td&gt;0.663300&lt;/td&gt;
      &lt;td&gt;89.184&lt;/td&gt;
      &lt;td&gt;9.308425&lt;/td&gt;
      &lt;td&gt;4.509008&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.628755&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;18.4&lt;/td&gt;
      &lt;td&gt;14.236807&lt;/td&gt;
      &lt;td&gt;0.180786&lt;/td&gt;
      &lt;td&gt;20.840972&lt;/td&gt;
      &lt;td&gt;2.990417&lt;/td&gt;
      &lt;td&gt;0.56489&lt;/td&gt;
      &lt;td&gt;4.135869&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;11.420316&lt;/td&gt;
      &lt;td&gt;1.280590&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12.315055&lt;/td&gt;
      &lt;td&gt;46.753105&lt;/td&gt;
      &lt;td&gt;0.087409&lt;/td&gt;
      &lt;td&gt;0.506201&lt;/td&gt;
      &lt;td&gt;89.184&lt;/td&gt;
      &lt;td&gt;46.691190&lt;/td&gt;
      &lt;td&gt;4.509008&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.218524&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;14.8&lt;/td&gt;
      &lt;td&gt;12.681650&lt;/td&gt;
      &lt;td&gt;0.261540&lt;/td&gt;
      &lt;td&gt;4.559753&lt;/td&gt;
      &lt;td&gt;2.990417&lt;/td&gt;
      &lt;td&gt;0.56489&lt;/td&gt;
      &lt;td&gt;3.458580&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;2.144661&lt;/td&gt;
      &lt;td&gt;0.719122&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12.315055&lt;/td&gt;
      &lt;td&gt;75.020729&lt;/td&gt;
      &lt;td&gt;0.030548&lt;/td&gt;
      &lt;td&gt;0.828211&lt;/td&gt;
      &lt;td&gt;89.184&lt;/td&gt;
      &lt;td&gt;21.924504&lt;/td&gt;
      &lt;td&gt;4.509008&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.279293&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;14.1&lt;/td&gt;
      &lt;td&gt;14.722096&lt;/td&gt;
      &lt;td&gt;0.104637&lt;/td&gt;
      &lt;td&gt;2.700840&lt;/td&gt;
      &lt;td&gt;2.990417&lt;/td&gt;
      &lt;td&gt;0.56489&lt;/td&gt;
      &lt;td&gt;3.269380&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;1.062468&lt;/td&gt;
      &lt;td&gt;0.657144&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;12.315055&lt;/td&gt;
      &lt;td&gt;88.887338&lt;/td&gt;
      &lt;td&gt;0.031402&lt;/td&gt;
      &lt;td&gt;0.540625&lt;/td&gt;
      &lt;td&gt;89.184&lt;/td&gt;
      &lt;td&gt;1.263040&lt;/td&gt;
      &lt;td&gt;4.509008&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.497191&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 37 columns&lt;/p&gt;
&lt;/div&gt;

&lt;h1&gt;Exploratory Data Analysis&lt;a name="exploratory"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;To begin my exploration, I wanted to identify any highly correlated features. I started by graphing a heatmap including only those features that had a &lt;strong&gt;correlation of .8 or greater&lt;/strong&gt; with one or more features.&lt;/p&gt;
&lt;p&gt;&lt;img alt="heatmap" src="/images/corr_heatmap.png"&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature Code&lt;/th&gt;
&lt;th&gt;Feature Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PCT_LACCESS_CHILD10&lt;/td&gt;
&lt;td&gt;Children, low access to store (%), 2010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PCT_LACCESS_SENIORS10&lt;/td&gt;
&lt;td&gt;Seniors, low access to store (%), 2010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PCT_LACCESS_LOWI10&lt;/td&gt;
&lt;td&gt;Low income &amp;amp; low access to store (%), 2010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PCT_LACCESS_POP10&lt;/td&gt;
&lt;td&gt;Population, low access to store (%), 2010&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Because all three of the other features were highly correlated with &lt;strong&gt;PCT_LACCESS_POP10&lt;/strong&gt;, I dropped the other three. After that, I felt confident that I would be able to avoid the worst interferences of collinearity.&lt;/p&gt;
&lt;p&gt;Next, I took some time to explore our target variable before transformation into a binary variable. How indeed had the diabetes rates by county changed from 2008 to 2013?&lt;/p&gt;
&lt;p&gt;&lt;img alt="diabetes histogram" src="/images/diabetes_hist.png"&gt;&lt;/p&gt;
&lt;p&gt;In this chart, the red line represents the &lt;strong&gt;11%&lt;/strong&gt; cutoff for inclusion in the Diabetes Belt. We can see at a glance that many more counties qualify in 2013 than in 2008.&lt;/p&gt;
&lt;p&gt;So, where are these counties concentrated? I chose to approach this question first using a set of parallel boxplots.&lt;/p&gt;
&lt;p&gt;&lt;img alt="diabetes boxplots by state" src="/images/diabetes_boxplots.png"&gt;&lt;/p&gt;
&lt;p&gt;Again, the red line represents the &lt;strong&gt;11%&lt;/strong&gt; Diabetes Belt cutoff. The US south and southeast are well represented above the line, while New England and the west are by and large in better shape.&lt;/p&gt;
&lt;p&gt;Finally, I transformed the target feature into binary categories for use in the classifier, and used them to create choropleth maps of the Diabetes Belt in 2008 and 2013 using geopandas and plotly.&lt;/p&gt;
&lt;h2&gt;The Diabetes Belt in 2008&lt;/h2&gt;
&lt;p&gt;&lt;img alt="map 2008" src="/images/map_2008.png"&gt;&lt;/p&gt;
&lt;h2&gt;The Diabetes Belt in 2013&lt;/h2&gt;
&lt;p&gt;&lt;img alt="map 2013" src="/images/map_2013.png"&gt;&lt;/p&gt;
&lt;p&gt;It is clear that the belt had expanded considerably from 2008 to 2013.&lt;/p&gt;
&lt;h1&gt;Feature Ranking&lt;a name="feature"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;In order to further narrow down the feature set and select only the most crucial factors, I used Random Forest to tank the features by gini index. This gave me a list of features sorted from the best contributing features to the worst.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Sort DataFrame by Gini Index, descending&lt;/span&gt;
&lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Gini&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ascending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;               Features      Gini
27   PCT_OBESE_ADULTS13  0.102188
16           PCT_SNAP12  0.093906
23            PCT_SBP09  0.063383
8    PCT_LACCESS_HHNV10  0.059547
17           SNAPSPTH12  0.055432
31           PCT_HISP10  0.054436
0         PCT_65OLDER10  0.053096
28        PCT_NHASIAN10  0.050246
20        PCT_NHBLACK10  0.043950
7            PCT_SFSP09  0.033113
18      PCT_18YOUNGER10  0.031913
15           CONVSPTH09  0.027032
9           PCT_CACFP09  0.026704
13        PCT_NHWHITE10  0.025728
14           PCT_NHPI10  0.024787
29           PCT_NHNA10  0.024062
5             WICSPTH12  0.022374
3     PCT_LACCESS_POP10  0.022209
6             PCT_WIC09  0.022059
1              FFRPTH09  0.021769
2             GROCPTH09  0.021536
4           RECFACPTH09  0.020892
19     SNAP_PART_RATE13  0.019416
10           SPECSPTH09  0.018830
12           PCT_NSLP09  0.018326
24          SUPERCPTH09  0.013437
22         PERCHLDPOV10  0.010694
11          SNAP_OAPP09  0.005829
30           SNAP_CAP09  0.004070
21              METRO13  0.003267
32             PERPOV10  0.002916
25          SNAP_BBCE09  0.002632
26  SNAP_REPORTSIMPLE09  0.000219
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, in order to clear out features that weren't contributing much, I used a backward selection algorithm to remove the features at the bottom of the list one by one until the accuracy of the model started to drop.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;titles&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;summary&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;# Features&lt;/th&gt;
      &lt;th&gt;Dropped Feature&lt;/th&gt;
      &lt;th&gt;Test Accuracy&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;NONE&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;SNAP_REPORTSIMPLE09&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;SNAP_BBCE09&lt;/td&gt;
      &lt;td&gt;0.861685&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;PERPOV10&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;METRO13&lt;/td&gt;
      &lt;td&gt;0.866455&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;SNAP_CAP09&lt;/td&gt;
      &lt;td&gt;0.863275&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;SNAP_OAPP09&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;PERCHLDPOV10&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;SUPERCPTH09&lt;/td&gt;
      &lt;td&gt;0.860095&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;PCT_NSLP09&lt;/td&gt;
      &lt;td&gt;0.863275&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;SPECSPTH09&lt;/td&gt;
      &lt;td&gt;0.863275&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;SNAP_PART_RATE13&lt;/td&gt;
      &lt;td&gt;0.863275&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;RECFACPTH09&lt;/td&gt;
      &lt;td&gt;0.861685&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;GROCPTH09&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;14&lt;/th&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;FFRPTH09&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;15&lt;/th&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;PCT_WIC09&lt;/td&gt;
      &lt;td&gt;0.868045&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;16&lt;/th&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;PCT_LACCESS_POP10&lt;/td&gt;
      &lt;td&gt;0.863275&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;17&lt;/th&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;WICSPTH12&lt;/td&gt;
      &lt;td&gt;0.868045&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;18&lt;/th&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;PCT_NHNA10&lt;/td&gt;
      &lt;td&gt;0.868045&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;19&lt;/th&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;PCT_NHPI10&lt;/td&gt;
      &lt;td&gt;0.871224&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;20&lt;/th&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;PCT_NHWHITE10&lt;/td&gt;
      &lt;td&gt;0.868045&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;21&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;PCT_CACFP09&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;22&lt;/th&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;CONVSPTH09&lt;/td&gt;
      &lt;td&gt;0.861685&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;23&lt;/th&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;PCT_18YOUNGER10&lt;/td&gt;
      &lt;td&gt;0.861685&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;24&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;PCT_SFSP09&lt;/td&gt;
      &lt;td&gt;0.855326&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;PCT_NHBLACK10&lt;/td&gt;
      &lt;td&gt;0.858506&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;26&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;PCT_NHASIAN10&lt;/td&gt;
      &lt;td&gt;0.864865&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;27&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;PCT_65OLDER10&lt;/td&gt;
      &lt;td&gt;0.844197&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;28&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;PCT_HISP10&lt;/td&gt;
      &lt;td&gt;0.844197&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;29&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;SNAPSPTH12&lt;/td&gt;
      &lt;td&gt;0.801272&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;30&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;PCT_LACCESS_HHNV10&lt;/td&gt;
      &lt;td&gt;0.763116&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;31&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;PCT_SBP09&lt;/td&gt;
      &lt;td&gt;0.777424&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;32&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;PCT_SNAP12&lt;/td&gt;
      &lt;td&gt;0.737679&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;# Features&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Test Accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;# of Features vs. Accuracy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Features&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Accuracy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Text(0, 0.5, &amp;#39;Accuracy&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_10_1.png"&gt;&lt;/p&gt;
&lt;p&gt;Having determined that the top seven features were likely to have the largest impact on the quality of the classifier that I wanted to build, I set out to isolate these features and explore their relationship to the target in greater depth.&lt;/p&gt;
&lt;h2&gt;Futher Exploration&lt;a name="further"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;So, what were these features that gave the most insight into diabetes risk?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;final&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Features&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])[:&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;final&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[&amp;#39;PCT_OBESE_ADULTS13&amp;#39;,
 &amp;#39;PCT_SNAP12&amp;#39;,
 &amp;#39;PCT_SBP09&amp;#39;,
 &amp;#39;PCT_LACCESS_HHNV10&amp;#39;,
 &amp;#39;SNAPSPTH12&amp;#39;,
 &amp;#39;PCT_HISP10&amp;#39;,
 &amp;#39;PCT_65OLDER10&amp;#39;]
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;final&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Variable Code&lt;/th&gt;
      &lt;th&gt;Variable Name&lt;/th&gt;
      &lt;th&gt;Category Name&lt;/th&gt;
      &lt;th&gt;Subcategory Name&lt;/th&gt;
      &lt;th&gt;Units&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;13&lt;/th&gt;
      &lt;td&gt;PCT_LACCESS_HHNV10&lt;/td&gt;
      &lt;td&gt;Households, no car &amp;amp; low access to store (%), ...&lt;/td&gt;
      &lt;td&gt;Access and Proximity to Grocery Store&lt;/td&gt;
      &lt;td&gt;Household Resources&lt;/td&gt;
      &lt;td&gt;Percent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;68&lt;/th&gt;
      &lt;td&gt;SNAPSPTH12&lt;/td&gt;
      &lt;td&gt;SNAP-authorized stores/1,000 pop, 2012&lt;/td&gt;
      &lt;td&gt;Store Availability&lt;/td&gt;
      &lt;td&gt;SNAP-authorized&lt;/td&gt;
      &lt;td&gt;# per 1,000 pop&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;96&lt;/th&gt;
      &lt;td&gt;PCT_SNAP12&lt;/td&gt;
      &lt;td&gt;SNAP participants (% pop), 2012*&lt;/td&gt;
      &lt;td&gt;Food Assistance&lt;/td&gt;
      &lt;td&gt;SNAP&lt;/td&gt;
      &lt;td&gt;Percent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;119&lt;/th&gt;
      &lt;td&gt;PCT_SBP09&lt;/td&gt;
      &lt;td&gt;School Breakfast Program participants (% pop),...&lt;/td&gt;
      &lt;td&gt;Food Assistance&lt;/td&gt;
      &lt;td&gt;School Breakfast Program&lt;/td&gt;
      &lt;td&gt;Percent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;254&lt;/th&gt;
      &lt;td&gt;PCT_OBESE_ADULTS13&lt;/td&gt;
      &lt;td&gt;Adult obesity rate, 2013&lt;/td&gt;
      &lt;td&gt;Health and Physical Activity&lt;/td&gt;
      &lt;td&gt;Health&lt;/td&gt;
      &lt;td&gt;Percent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;264&lt;/th&gt;
      &lt;td&gt;PCT_HISP10&lt;/td&gt;
      &lt;td&gt;% Hispanic, 2010&lt;/td&gt;
      &lt;td&gt;Socioeconomic Characteristics&lt;/td&gt;
      &lt;td&gt;Race &amp;amp; Age&lt;/td&gt;
      &lt;td&gt;Percent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;268&lt;/th&gt;
      &lt;td&gt;PCT_65OLDER10&lt;/td&gt;
      &lt;td&gt;% Population 65 years or older, 2010&lt;/td&gt;
      &lt;td&gt;Socioeconomic Characteristics&lt;/td&gt;
      &lt;td&gt;Race &amp;amp; Age&lt;/td&gt;
      &lt;td&gt;Percent&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Examining these features, I elected to group them into four categories for understanding:
1. &lt;strong&gt;Obesity&lt;/strong&gt;
2. &lt;strong&gt;Food Access&lt;/strong&gt;
3. &lt;strong&gt;Food Assistance&lt;/strong&gt;
4. &lt;strong&gt;Race &amp;amp; Age&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;How then were these factors related to the diabetes belt? I set out to explore with the aid of boxplots. The function I used to make these plots may be found in my GitHub repository.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;boxplotter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obesity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Obesity - No Belt vs. Belt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_16_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Here, the relationship is clear. The median county diabetes rate in the Belt is at least 5% greater than outside of it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;boxplotter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;access&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Food Access - No Belt vs. Belt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_18_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Clearly, household access to store is an important factor, with &lt;strong&gt;lower access overall in the belt.&lt;/strong&gt; SNAP-authorized stores may be thought of here as a &lt;strong&gt;proxy for poverty&lt;/strong&gt;, as it is likely that there are more such stores in impoverished areas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;boxplotter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;food_assist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Food Assistance - No Belt vs. Belt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_20_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Again, these measures are probably best thought of as &lt;strong&gt;proxies for poverty,&lt;/strong&gt; though it might take more domain knowledge to really know what is going on. Still, rates seem to be generally higher on the belt than off of it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;boxplotter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;race_age&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Race &amp;amp; Age - No Belt vs. Belt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="/images/output_22_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Here, larger Hispanic populations were better represented off of the belt. Meanwhile, older populations were slightly better represented on the belt.&lt;/p&gt;
&lt;h1&gt;Building a Classifier&lt;a name="building"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;At this point, I felt comfortable taking a crack at developing a model. In order to do this, I built a pipeline to test four popular algorithms for classification:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Logistic Regression&lt;/li&gt;
&lt;li&gt;Naive Bayes&lt;/li&gt;
&lt;li&gt;Support Vector Machines&lt;/li&gt;
&lt;li&gt;Random Forest&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# instantiate our models&lt;/span&gt;
&lt;span class="n"&gt;models&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Logistic Regression&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;solver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;liblinear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Naive Bayes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;GaussianNB&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SVM&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gamma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;scale&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Random Forest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;results_accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;results_recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="c1"&gt;# perform kfold validation on our data, applying each model 10 times and returning the means of the accuracy and recall scores&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;kfold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_selection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;KFold&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_splits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;cv_results_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_selection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kfold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;results_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cv_results_acc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;cv_results_rec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_selection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kfold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scoring&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;recall&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;results_recall&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cv_results_rec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;{}: Mean Accuracy: {}; Mean Recall: {}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results_accuracy&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results_recall&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;Logistic&lt;/span&gt; &lt;span class="nt"&gt;Regression&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;7965726417955719&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;8002437773643095&lt;/span&gt;
&lt;span class="nt"&gt;Naive&lt;/span&gt; &lt;span class="nt"&gt;Bayes&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;7736639369123445&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;8481707175206757&lt;/span&gt;
&lt;span class="nt"&gt;SVM&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;800387220705692&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;7647862197476227&lt;/span&gt;
&lt;span class="nt"&gt;Random&lt;/span&gt; &lt;span class="nt"&gt;Forest&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;7914750783540592&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;Mean&lt;/span&gt; &lt;span class="nt"&gt;Recall&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;7639746311963183&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All four models did remarkably well. In order to get a clearer sense of what was going on, I produced boxplots of the individual scores from the kfold validation step.&lt;/p&gt;
&lt;p&gt;&lt;img alt="algorithm boxplots" src="/images/algorithm_comparison.png"&gt;&lt;/p&gt;
&lt;p&gt;Surprisingly (to me), logistic regression performed the best overall of the four! Because it is a simple, fast algorithm that is robust against overfitting, and because the fact that it performed well probably means that the data is well-suited to what is essentially a linear approach, I felt comfortable selecting this as the final model with a &lt;strong&gt;mean accuracy of 80%.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Exploring the confusion matrix confirmed that the model was well-tuned for accuracy, with similar numbers of false positives and false negatives:&lt;/p&gt;
&lt;p&gt;&lt;img alt="logreg confusion matrix" src="/images/conf_logreg.png"&gt;&lt;/p&gt;
&lt;h1&gt;Wrap-Up&lt;a name="wrap"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Given the wealth of data in the USDA's Food Environment Atlas, I have found that it is possible to construct a classifier that will determine whether a US county qualifies as a member of the CDC's Diabetes Belt with &lt;strong&gt;~80% accuracy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The top categories of features appear to be &lt;strong&gt;obesity, food access, food assistance, and race/age&lt;/strong&gt;. Some of these may be proxies for the effect of &lt;strong&gt;poverty&lt;/strong&gt;, rather than causes in of themselves, but to assess this would require domain expertise and the investment of greater material resources.&lt;/p&gt;
&lt;p&gt;I observed comparably excellent performance from all classifiers trialed, and ended up using &lt;strong&gt;logistic regression&lt;/strong&gt;, which is fast, accurate in this case, and robust against overfitting.&lt;/p&gt;
&lt;h2&gt;Recommendations&lt;a name="recommendations"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Based off of these findings, my recommendations to those who are working to identify diabetes hotspots in the US are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;A high rate of obesity in a county is the single best indicator for whether diabetes is likely to be a problem.&lt;/strong&gt; This is already well known, but it is valuable to know that these findings confirm that is the case.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vulnerable populations such as the elderly and families without transportation or easy access to stores are at a special risk for diabetes&lt;/strong&gt;, and where this demographic information is available, it is worth giving these populations special attention preemptively.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data on food access and socioeconomic factors are of demonstrable use in determining level of risk of diabetes in a county.&lt;/strong&gt; It is worth continuing to gather this data, and the more of it is available for public access, the better!&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Possible Next Steps&lt;a name="possible"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I feel confident that with more data and finer tuning, even more accurate models might be built from this data. Specifically, with more time to devote I would consider the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;More comprehensive hyperparameter tuning for SVM and Random Forest.&lt;/strong&gt; I ran a grid search on the hyperparameters for SVM, and tried a small group of different possibilities for Random Forest, but I could have done more, and might have wrung out better performance. I'm also curious about Bayesian hyperparameter optimization, and wonder whether that might lead me in a more fruitful direction.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engineering new features from multi-survey differences.&lt;/strong&gt; Features that consisted of the change of a measurement from one year or another could yield useful information about whether a particular county is trending better or worse, or perhaps whether or not it is the beneficiary of some kind of investment. While these are of questionable use as they are, as a transformed categorical variable, they might yield some fruit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Filling out features with null values instead of dropping them entirely.&lt;/strong&gt; There were a large number of interesting features that suffered from null values, which I did not consider when building this classifier. It might be interesting to see whether any of them provide useful enough information to be worth backfilling. Ultimately, my hope is that future USDA surveys will render this unnecessary.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;</content></entry></feed>